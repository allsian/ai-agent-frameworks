{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99eee7a2",
   "metadata": {},
   "source": [
    "# MCP ToolSpec\n",
    "\n",
    "This tool connects to MCP Servers and allows an Agent to call the tools provided by MCP Servers.\n",
    "\n",
    "First, you need to run an MCP Server. You can use the provided `mcp_server.py` script to start a server that supports SSE (Server-Sent Events).\n",
    "\n",
    "```bash\n",
    "# run the server\n",
    "python mcp_server.py --server_type=sse\n",
    "```\n",
    "\n",
    "And run the cell bellow to setup the env vars and imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe0b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path and temporarily change to it for settings import\n",
    "sys.path.append('..')\n",
    "os.chdir('..')\n",
    "from settings import settings\n",
    "os.chdir('mcp')  # Change back to mcp directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6ef6b",
   "metadata": {},
   "source": [
    "In this example, we will create a toy example with an agent that can use the tools provided by the MCP Server.\n",
    "\n",
    "It's built using the `AgentWorkflow` class from LlamaIndex. If that's new to you, you can [read more about it](https://docs.llamaindex.ai/en/stable/examples/agent/agent_workflow_basic/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6088f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f519717e-c620-4e32-9729-99740b648556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent, ToolCallResult, ToolCall\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an F1 Expert AI assistant.\n",
    "\n",
    "You should use the tools provided to you to answer user questions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def get_agent(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can get information about F1 drivers.\",\n",
    "        tools=tools,\n",
    "        llm=llm,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "\n",
    "async def handle_user_message(\n",
    "    message_content: str,\n",
    "    agent: FunctionAgent,\n",
    "    agent_context: Context,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    handler = agent.run(message_content, ctx=agent_context)\n",
    "    async for event in handler.stream_events():\n",
    "        if verbose and type(event) == ToolCall:\n",
    "            print(f\"Calling tool {event.tool_name} with kwargs {event.tool_kwargs}\")\n",
    "        elif verbose and type(event) == ToolCallResult:\n",
    "            print(f\"Tool {event.tool_name} returned {event.tool_output}\")\n",
    "\n",
    "    response = await handler\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a69bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# We consider there is a mcp server running on 127.0.0.1:8000, or you can use the mcp client to connect to your own mcp server.\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# get the agent\n",
    "agent = await get_agent(mcp_tool)\n",
    "\n",
    "# create the agent context\n",
    "agent_context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  driver 44 info\n",
      "Calling tool get_driver_info with kwargs {'driver_number': 44}\n",
      "Tool get_driver_info returned meta=None content=[TextContent(type='text', text='{\\n  \"id\": \"44\",\\n  \"full_name\": \"Lewis HAMILTON\",\\n  \"name_acronym\": \"HAM\",\\n  \"team_name\": \"Ferrari\"\\n}', annotations=None, meta=None)] structuredContent={'id': '44', 'full_name': 'Lewis HAMILTON', 'name_acronym': 'HAM', 'team_name': 'Ferrari'} isError=False\n",
      "Agent:  Driver 44 is Lewis Hamilton. Here are the details:\n",
      "\n",
      "- **Full Name:** Lewis HAMILTON\n",
      "- **Acronym:** HAM\n",
      "- **Team Name:** Ferrari\n",
      "\n",
      "(Note: Lewis Hamilton is actually associated with Mercedes, not Ferrari. Please verify the team information if needed.)\n"
     ]
    }
   ],
   "source": [
    "# Run the agent!\n",
    "while True:\n",
    "    user_input = input(\"Enter your message: \") # try \"Driver 1 information\", then \"exit\" to stop\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(\"User: \", user_input)\n",
    "    response = await handle_user_message(user_input, agent, agent_context, verbose=True)\n",
    "    print(\"Agent: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c44895",
   "metadata": {},
   "source": [
    "Here, we can see the agent is calling the `get_driver_info` tool to get the driver info! **This tool is running remotely on the MCP server.**\n",
    "\n",
    "The `MCPToolSpec` is connecting to the MCP server and creating `FunctionTool`s for each tool that is registered on the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a84adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_driver_info Get F1 driver info by driver ID\n",
      "\n",
      "    Args:\n",
      "        driver_id(str): The ID of the driver to get the info for.\n",
      "    Returns:\n",
      "        DriverInfo: The info of the specified driver.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "tools = await mcp_tool.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7be78",
   "metadata": {},
   "source": [
    "You can also limit the tools that the `MCPToolSpec` will create by passing a list of tool names to the `MCPToolSpec` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4929af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tools available are allowed by the MCP client.\n"
     ]
    }
   ],
   "source": [
    "mcp_tool = McpToolSpec(client=mcp_client, allowed_tools=[\"some fake tool\"])\n",
    "tools = await mcp_tool.to_tool_list_async()\n",
    "\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)\n",
    "if not tools:\n",
    "    print(\"No tools available are allowed by the MCP client.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
